{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "输入3个句子，每个句子由5个单词构成，每个单词词向量10维\n",
    "batch=3, seq_len=5, Embedding=10\n",
    "\"\"\"\n",
    "# Hyper-parameters  词向量维数10，隐藏元维度20,2个LSTM隐藏层，双向LSTM\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape： torch.Size([5, 3, 40])\n",
      "hn shape： torch.Size([4, 3, 20])\n",
      "cn shape： torch.Size([4, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "# BiLSTM Model\n",
    "bilstm = nn.LSTM(input_size=10,hidden_size=20,num_layers=2,bidirectional=True)\n",
    "\n",
    "# Input sentence\n",
    "input = torch.randn(5, 3, 10)\n",
    "\n",
    "# Set initial hidden and cell states \n",
    "h0 = torch.randn(4, 3, 20)  # [bidirection*num_layers, batch_size, hidden_size]\n",
    "c0 = torch.randn(4, 3, 20)  # [bidirection*num_layers, batch_size, hidden_size]\n",
    "\n",
    "# 这里有2层lstm，output是最后一层lstm的每个词向量对应隐藏层的输出，与层数无关，只与序列长度有关\n",
    "output, (hn, cn) = bilstm(input, (h0, c0))\n",
    "print(\"output shape：\", output.shape)  # shape：torch.Size([5,3,40]),[seq_len,batch_size,2*hidden_size]\n",
    "print(\"hn shape：\", hn.shape)  # shape：torch.Size([4,3,20]),[bidirection*num_layers,batch_size,hidden_size]\n",
    "print(\"cn shape：\", cn.shape)  # shape：torch.Size([4,3,20]),[bidirection*num_layers,batch_size,hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([[-0.0896,  0.1432],\n",
      "        [-0.0853, -0.2030],\n",
      "        [ 0.0126, -0.0179]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Binary classification\n",
    "output = output.permute(1, 0, 2)  # torch.Size([3,5,40]),[batch_size,seq_len,2*hidden_size]\n",
    "output = output.contiguous()\n",
    "batch_size = output.size(0)\n",
    "output = output.view(batch_size, -1)  # torch.Size([3,200]),[batch_size,seq_len*2*hidden_size]\n",
    "fully_connected = nn.Linear(200, 2)\n",
    "# fc\n",
    "output = fully_connected(output)\n",
    "print(output.shape)  # torch.Size([3,2]),[batch_size,class]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
